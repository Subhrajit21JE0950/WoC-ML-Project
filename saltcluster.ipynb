{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "saltcluster.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cz9qWTxBVqyk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ2fzNrvIHCE",
        "outputId": "0c5ff3de-517b-4e02-ebb1-e850a7ea46a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(arr,cou):\n",
        "  sum_elements=np.sum(arr)\n",
        "  if(sum_elements!=0):\n",
        "   mean=sum_elements/cou\n",
        "   d=arr-mean\n",
        "   std=np.sum(np.multiply(d,d))\n",
        "   stdev=(std/cou)**0.5\n",
        "   arr=(arr-mean)*(1/stdev)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "Edktx1lzWRWO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(temp):\n",
        " y_train=temp['1']\n",
        " x_train=temp\n",
        " del x_train['1']\n",
        "\n",
        " X_train=x_train.to_numpy()\n",
        " Y_train=y_train.to_numpy()\n",
        " r,c=X_train.shape\n",
        " #X_train=np.concatenate((np.ones((r,1)),X_train),axis=1)\n",
        " \n",
        " X_train=X_train.T\n",
        " for i in range(c):\n",
        "  if(i==0):\n",
        "   continue \n",
        "  X_train[i]=normalize(X_train[i],r)\n",
        " X_train=X_train.T\n",
        " \n",
        " return X_train,Y_train"
      ],
      "metadata": {
        "id": "_36uUYLPWQgw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/emnist-letters-train (1).csv')\n",
        "temp1=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/emnist-letters-test.csv')\n",
        "\n",
        "y1 = temp1['1']\n",
        "Y1 = np.array(y1)\n",
        "j = 5000\n",
        "x,y=get_data(temp)\n",
        "X = np.array(pd.DataFrame(x).head(j))\n",
        "Y = np.array(pd.DataFrame(y).head(j))\n",
        "x_train = X\n",
        "y_train = Y\n",
        "\n",
        "x1,y1=get_data(temp1)\n",
        "X1 = np.array(pd.DataFrame(x1).head(j))\n",
        "Y1 = np.array(pd.DataFrame(y1).head(j))\n",
        "x_test = X1\n",
        "y_test = Y1"
      ],
      "metadata": {
        "id": "m2lJorZlWEtJ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(x1, x2):\n",
        "    return np.sqrt(np.sum((x1 - x2) ** 2))"
      ],
      "metadata": {
        "id": "9AjpdE8iEfYd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KMeans:\n",
        "    def __init__(self, K=5, max_iters=100, plot_steps=False):\n",
        "        self.K = K\n",
        "        self.max_iters = max_iters\n",
        "        self.plot_steps = plot_steps\n",
        "\n",
        "        # list of sample indices for each cluster\n",
        "        self.clusters = [[] for _ in range(self.K)]\n",
        "        # the centers (mean feature vector) for each cluster\n",
        "        self.centroids = []\n",
        "\n",
        "    def predict(self, X):\n",
        "        self.X = X\n",
        "        self.n_samples, self.n_features = X.shape\n",
        "\n",
        "        # initialize\n",
        "        np.random.seed(42)\n",
        "        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)\n",
        "        self.centroids = [self.X[idx] for idx in random_sample_idxs]\n",
        "\n",
        "        # Optimize clusters\n",
        "        for _ in range(self.max_iters):\n",
        "            # Assign samples to closest centroids (create clusters)\n",
        "            self.clusters = self._create_clusters(self.centroids)\n",
        "            # Calculate new centroids from the clusters\n",
        "            centroids_old = self.centroids\n",
        "            self.centroids = self._get_centroids(self.clusters)\n",
        "\n",
        "            # check if clusters have changed\n",
        "            if self._is_converged(centroids_old, self.centroids):\n",
        "                break\n",
        "        # Classify samples as the index of their clusters\n",
        "        return self._get_cluster_labels(self.clusters)\n",
        "\n",
        "    def _get_cluster_labels(self, clusters):\n",
        "        # each sample will get the label of the cluster it was assigned to\n",
        "        labels = np.empty(self.n_samples)\n",
        "\n",
        "        for cluster_idx, cluster in enumerate(clusters):\n",
        "            for sample_index in cluster:\n",
        "                labels[sample_index] = cluster_idx\n",
        "        return labels\n",
        "\n",
        "    def _create_clusters(self, centroids):\n",
        "        # Assign the samples to the closest centroids to create clusters\n",
        "        clusters = [[] for _ in range(self.K)]\n",
        "        for idx, sample in enumerate(self.X):\n",
        "            centroid_idx = self._closest_centroid(sample, centroids)\n",
        "            clusters[centroid_idx].append(idx)\n",
        "        return clusters\n",
        "\n",
        "    def _closest_centroid(self, sample, centroids):\n",
        "        # distance of the current sample to each centroid\n",
        "        distances = [euclidean_distance(sample, point) for point in centroids]\n",
        "        closest_index = np.argmin(distances)\n",
        "        return closest_index\n",
        "\n",
        "    def _get_centroids(self, clusters):\n",
        "        # assign mean value of clusters to centroids\n",
        "        centroids = np.zeros((self.K, self.n_features))\n",
        "        for cluster_idx, cluster in enumerate(clusters):\n",
        "            cluster_mean = np.mean(self.X[cluster], axis=0)\n",
        "            centroids[cluster_idx] = cluster_mean\n",
        "        return centroids\n",
        "\n",
        "    def _is_converged(self, centroids_old, centroids):\n",
        "        # distances between each old and new centroids, fol all centroids\n",
        "        distances = [\n",
        "            euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)\n",
        "        ]\n",
        "        return sum(distances) == 0"
      ],
      "metadata": {
        "id": "dZ4ouxLhG88o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_train,y_pred):\n",
        "  success=0\n",
        "  for i in range(y_train.shape[0]):\n",
        "    if(y_pred[i]==y_train[i]):\n",
        "      success+=1\n",
        "  acc = 30*(success/y_train.shape[0])\n",
        "  return acc"
      ],
      "metadata": {
        "id": "pGwQ-YoYTW-J"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clusters = len(np.unique(y_train))\n",
        "k = KMeans(K=clusters, max_iters=1000, plot_steps=True)\n",
        "y_pred = (k.predict(x_test))\n",
        "print(100*(accuracy(y_test,y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aeETxsXHIcD",
        "outputId": "7df54c75-af8d-4c2f-a1a8-b890a73f5913"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84.6\n"
          ]
        }
      ]
    }
  ]
}