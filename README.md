ML Project IIT(ISM) DHANBAD
Report  :                                                                                                                                 
This is the report about my findings regarding the project:
â€¢	Linear Regression uses gradient descent method to continuously update parameters. The hyperparameters are learning rate and number of iterations. I have found that
increasing learning rate makes the cost function minimise rapidly but after a certain point it oscillates. Whereas lower learning rate makes the cost function minimise
very slowly. The correct combination is found by hit and trial method. I have also used standardization on the training data. The cost function is 2522.

<img src= "https://prnt.sc/-DTDNKjNKacq" width="250" height="250" />



