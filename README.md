ML Project IIT(ISM) DHANBAD
Report  :                                                                                                                                 
This is the report about my findings regarding the project:
â€¢	Linear Regression uses gradient descent method to continuously update parameters. The hyperparameters are learning rate and number of iterations. I have found that
increasing learning rate makes the cost function minimise rapidly but after a certain point it oscillates. Whereas lower learning rate makes the cost function minimise
very slowly. The correct combination is found by hit and trial method. I have also used standardization on the training data. The cost function is 2522.
![image](https://user-images.githubusercontent.com/103888763/163828829-271510f4-a532-45b7-b684-d7648032fb1c.png)


